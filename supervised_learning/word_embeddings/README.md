# Word Embeddings

This repository contains implementations of various word embedding techniques used in Natural Language Processing (NLP). Each implementation explores different approaches to converting text data into meaningful numerical representations.

## Tasks

| Task | Name | File | Description |
|------|------|------|-------------|
| 0 | Bag of Words | [0-bag_of_words.py](/supervised_learning/word_embeddings/0-bag_of_words.py) | Implementation of the Bag of Words (BoW) embedding matrix |
| 1 | TF-IDF | [1-tf_idf.py](/supervised_learning/word_embeddings/1-tf_idf.py) | Creation of TF-IDF (Term Frequency-Inverse Document Frequency) embeddings |
| 2 | Word2Vec Training | [2-word2vec.py](/supervised_learning/word_embeddings/2-word2vec.py) | Training implementation of the Word2Vec model using Gensim |
| 3 | Word2Vec to Keras | [3-gensim_to_keras.py](/supervised_learning/word_embeddings/3-gensim_to_keras.py) | Conversion utility from Gensim Word2Vec to Keras Embedding layer |
| 4 | FastText | [4-fasttext.py](/supervised_learning/word_embeddings/4-fasttext.py) | Implementation and training of the FastText model using Gensim |
| 5 | ELMo | [5-elmo.py](/supervised_learning/word_embeddings/5-elmo.py) | Multiple choice questions and answers about ELMo model training |

